{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Housing Price Data Exploration Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "This notebook addresses **Business Requirement 1** of the project: understanding the factors that influence house prices. To do this, we perform an exploratory data analysis (EDA) and correlation study to identify which features are most strongly related to the target variable `SalePrice`.\n",
        "\n",
        "We aim to:\n",
        "- Assess the structure and quality of the dataset\n",
        "- Encode categorical variables appropriately\n",
        "- Quantify the relationship between predictors and `SalePrice` using Pearson and Spearman correlation\n",
        "- Visualize key patterns and trends\n",
        "- Select features for use in modeling, based on statistical strength and visual insight\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- `outputs/datasets/collection/house_prices_records.csv`\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Numeric summary and structure of the dataset\n",
        "- Correlation tables using Pearson and Spearman methods\n",
        "- Boxplots and scatter plots of the top correlated features\n",
        "- A parallel categories plot to visualize multi-dimensional relationships\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with `os.getcwd()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* `os.path.dirname()` gets the parent directory\n",
        "* `os.chir()` defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"outputs/datasets/collection/house_prices_records.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are interested in learning more about the dataset. We want to check the type and distribution of variables, missing levels, and what these variables mean in a business context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect types and nulls\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we generate a Pandas Summary for all columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary = df.describe(include='all').transpose()\n",
        "summary['missing_values'] = df.isnull().sum()\n",
        "summary[['count', 'unique', 'top', 'freq', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'missing_values']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The summary shows the dataset has 24 features with a mix of numerical and categorical data. Key features such as `GrLivArea`, `TotalBsmtSF`, and `GarageArea` are fully populated and numeric, making them good candidates for modeling. Some variables, like `2ndFlrSF`, `BedroomAbvGr`, and `GarageYrBlt`, contain missing values that will require preprocessing. A few categorical features (e.g., `BsmtExposure`, `GarageFinish`, and `KitchenQual`) have a limited number of distinct values, which are suitable for encoding. Additionally, columns like `EnclosedPorch` and `WoodDeckSF` show a high number of missing entries, indicating they may be sparsely used or non-essential for all records.\n",
        "\n",
        "This summary provides a strong foundation for selecting the most relevant variables for further analysis and preparing them appropriately.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ProfileReport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "from IPython.display import IFrame\n",
        "\n",
        "# Create a profile report\n",
        "profile = ProfileReport(df=df, minimal=True)\n",
        "profile.to_notebook_iframe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Variables for Correlation Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To evaluate how different features relate to `SalePrice`, we need to ensure all variables are numeric. For that:\n",
        "- **Ordinal variables** like `KitchenQual` will be mapped to ordered integers.\n",
        "- **Nominal categorical variables** (like `BsmtExposure`, `GarageFinish`) will be one-hot encoded.\n",
        "- **Missing values** must be handled before transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Handle missing values in categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_vars = ['BsmtExposure', 'GarageFinish', 'BsmtFinType1']\n",
        "df[categorical_vars] = df[categorical_vars].fillna('Missing')\n",
        "\n",
        "print(\"Number of missing values in each categorical column\\n\")\n",
        "print(df[categorical_vars].isnull().sum())\n",
        "print(\"\\nCheck the first 20 rows of the categorical variables\\n\")\n",
        "df[categorical_vars].head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ordinal mapping for KitchenQual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qual_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
        "df['KitchenQual'] = df['KitchenQual'].map(qual_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['KitchenQual'].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One-hot encoding nominal categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.encoding import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(variables=categorical_vars, drop_last=False)\n",
        "df_encoded = encoder.fit_transform(df)\n",
        "\n",
        "df_encoded.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now have the dataset represented with only numerical values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nCheck the first 10 rows of the encoded categorical variables\\n\")\n",
        "df_encoded.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the dataset contains numeric representations of all relevant features and is ready for correlation analysis.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correlation Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute both **Pearson** (linear relationships) and **Spearman** (monotonic relationships) correlations.\n",
        "We know this command returns a pandas series and the first item is the correlation between Churn and Churn, which happens to be 1, so we exclude that with [1:]\n",
        "We sort values considering the absolute value, by setting key=abs\n",
        "\n",
        "Calculate Pearson correlation with SalePrice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = df_encoded.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:]\n",
        "print(\"Top Pearson correlations with SalePrice:\\n\", corr_pearson.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate Spearman correlation with `SalePrice`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman = df_encoded.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:]\n",
        "print(\"\\nTop Spearman correlations with SalePrice:\\n\", corr_spearman.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select Top Correlated Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of selecting a fixed number of top variables, we define a correlation threshold (≥ 0.5) and select all variables that meet or exceed this threshold in either Pearson or Spearman correlation. This allows us to retain variables with meaningful relationships to `SalePrice` while staying flexible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_threshold = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we get the variables above this threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "strong_pearson = corr_pearson[abs(corr_pearson) >= corr_threshold].index.tolist()\n",
        "strong_spearman = corr_spearman[abs(corr_spearman) >= corr_threshold].index.tolist()\n",
        "\n",
        "# Combine and remove duplicates\n",
        "selected_vars = list(set(strong_pearson + strong_spearman))\n",
        "print(\"Selected variables based on correlation threshold:\\n\", selected_vars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ppscore as pps\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "# Compute PPS matrix for the dataset\n",
        "pps_matrix = pps.matrix(df_encoded)[['x', 'y', 'ppscore']]\n",
        "\n",
        "# Filter for relationships where the target is SalePrice\n",
        "pps_saleprice = pps_matrix[pps_matrix['y'] == 'SalePrice']\n",
        "\n",
        "# Pivot the data for heatmap visualization\n",
        "pps_pivot = pps_saleprice.pivot(index='x', columns='y', values='ppscore')\n",
        "\n",
        "# # Plot the heatmap\n",
        "# plt.figure(figsize=(10, 8))\n",
        "# sns.heatmap(pps_pivot, annot=True, cmap='coolwarm', cbar=True)\n",
        "# plt.title('PPS Heatmap for Features with SalePrice as Target', fontsize=14)\n",
        "# plt.xlabel('Target')\n",
        "# plt.ylabel('Feature')\n",
        "# plt.show()\n",
        "# Remove 'SalePrice' from the list of features in the PPS matrix\n",
        "pps_pivot = pps_pivot.drop(index='SalePrice')\n",
        "\n",
        "# Re-plot the heatmap without 'SalePrice'\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(pps_pivot, annot=True, cmap='coolwarm', cbar=True)\n",
        "plt.title('PPS Heatmap for Features with SalePrice as Target (Excluding SalePrice)', fontsize=14)\n",
        "plt.xlabel('Target')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# Compute the full PPS matrix for the dataset\n",
        "pps_full_matrix = pps.matrix(df)\n",
        "\n",
        "# Pivot the data for heatmap visualization\n",
        "pps_full_pivot = pps_full_matrix.pivot(index='x', columns='y', values='ppscore')\n",
        "\n",
        "# Plot the heatmap\n",
        "# plt.figure(figsize=(15, 12))\n",
        "# sns.heatmap(pps_full_pivot, annot=False, cmap='coolwarm', cbar=True)\n",
        "# plt.title('PPS Heatmap for All Features', fontsize=16)\n",
        "# plt.xlabel('Target Features')\n",
        "# plt.ylabel('Predictor Features')\n",
        "# plt.show()\n",
        "# Re-plot the heatmaps with annotations\n",
        "# plt.figure(figsize=(10, 8))\n",
        "# sns.heatmap(pps_pivot, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
        "# plt.title('PPS Heatmap for Features with SalePrice as Target (Annotated)', fontsize=14)\n",
        "# plt.xlabel('Target')\n",
        "# plt.ylabel('Feature')\n",
        "# plt.show()\n",
        "\n",
        "# Remove squares with values <= 0\n",
        "pps_full_pivot_filtered = pps_full_pivot[pps_full_pivot > 0.2]\n",
        "\n",
        "# Re-plot the heatmap with filtered values\n",
        "plt.figure(figsize=(15, 12))\n",
        "sns.heatmap(pps_full_pivot_filtered, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
        "plt.title('PPS Heatmap for All Features (Filtered, Annotated)', fontsize=16)\n",
        "plt.xlabel('Target Features')\n",
        "plt.ylabel('Predictor Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA on Selected Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We visually inspect the relationship between each selected variable and the target (`SalePrice`).\n",
        "\n",
        "We use boxplots for discrete ordinal features with a small number of levels (like `KitchenQual`), and scatterplots for continuous variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df[selected_vars].isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "def plot_scatter(df, x, y):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.scatterplot(data=df, x=x, y=y, alpha=0.6)\n",
        "    sns.regplot(data=df, x=x, y=y, scatter=False, color='red', line_kws={\"linewidth\": 1})\n",
        "    plt.title(f\"{x} vs {y} with Regression Line\", fontsize=14)\n",
        "    plt.xlabel(x)\n",
        "    plt.ylabel(y)\n",
        "    plt.grid(True, linestyle='--', linewidth=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_box(df, x, y):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.boxplot(data=df, x=x, y=y)\n",
        "    plt.title(f\"{x} vs {y}\", fontsize=14)\n",
        "    plt.xlabel(x)\n",
        "    plt.ylabel(y)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Apply different plots depending on variable type or value range\n",
        "for col in selected_vars:\n",
        "    if df[col].nunique() <= 10:\n",
        "        print(f\"Plotting boxplot for {col} vs SalePrice\")\n",
        "        plot_box(df, col, 'SalePrice')\n",
        "    else:\n",
        "        plot_scatter(df, col, 'SalePrice')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Parallel Plot with Binned Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Binning Key Numeric Features for Visualization\n",
        "\n",
        "To improve interpretability in the parallel categories plot, we grouped continuous variables into meaningful ranges using `ArbitraryDiscretiser`:\n",
        "\n",
        "- **`GrLivArea`**, **`GarageArea`**, **`TotalBsmtSF`**, and **`YearBuilt`** were binned into custom-defined intervals reflecting size or time periods.\n",
        "- Each binned variable was then labeled using `pd.Categorical` to define a clear order for plotting.\n",
        "- These bins simplify the visual structure and reduce clutter, allowing us to analyze house price trends across grouped feature ranges rather than individual raw values.\n",
        "\n",
        "This step prepares the dataset for a cleaner, more insightful visualization of relationships between multiple housing attributes and `SalePrice`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.discretisation import ArbitraryDiscretiser\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Columns to bin (with source already defined as df_encoded)\n",
        "df_binned = df_encoded[['GrLivArea', 'GarageArea', 'TotalBsmtSF', 'YearBuilt', 'OverallQual', 'SalePrice']].copy()\n",
        "\n",
        "# Define binning dictionary\n",
        "binning_dict = {\n",
        "    'GrLivArea': [-np.inf, 1000, 1500, 2000, 2500, np.inf],\n",
        "    'GarageArea': [-1, 300, 500, 700, np.inf],\n",
        "    'TotalBsmtSF': [-np.inf, 500, 1000, 1500, np.inf],\n",
        "    'YearBuilt': [1800, 1950, 1970, 1990, 2010, np.inf]\n",
        "}\n",
        "\n",
        "# Apply binning\n",
        "disc = ArbitraryDiscretiser(binning_dict=binning_dict)\n",
        "df_binned = disc.fit_transform(df_binned)\n",
        "\n",
        "# Replace bin codes with readable labels using pd.Categorical\n",
        "df_binned['GrLivArea'] = pd.Categorical(\n",
        "    df_binned['GrLivArea'].replace({0: '<1000', 1: '1000-1500', 2: '1500-2000', 3: '2000-2500', 4: '2500+'}),\n",
        "    categories=['<1000', '1000-1500', '1500-2000', '2000-2500', '2500+'],\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "df_binned['GarageArea'] = pd.Categorical(\n",
        "    df_binned['GarageArea'].replace({0: '<300', 1: '300-500', 2: '500-700', 3: '700+'}),\n",
        "    categories=['<300', '300-500', '500-700', '700+'],\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "df_binned['TotalBsmtSF'] = pd.Categorical(\n",
        "    df_binned['TotalBsmtSF'].replace({0: '<500', 1: '500-1000', 2: '1000-1500', 3: '1500+'}),\n",
        "    categories=['<500', '500-1000', '1000-1500', '1500+'],\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "df_binned['YearBuilt'] = pd.Categorical(\n",
        "    df_binned['YearBuilt'].replace({0: '<1950', 1: '1950-1970', 2: '1970-1990', 3: '1990-2010', 4: '2010+'}),\n",
        "    categories=['<1950', '1950-1970', '1970-1990', '1990-2010', '2010+'],\n",
        "    ordered=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parallel Categories Plot (Aggregated by Median SalePrice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "\n",
        "# Aggregate by combinations to get median SalePrice\n",
        "agg_df = df_binned.groupby(\n",
        "    ['GrLivArea', 'OverallQual', 'GarageArea', 'TotalBsmtSF', 'YearBuilt'],\n",
        "    observed=True\n",
        ").agg({'SalePrice': 'median'}).reset_index()\n",
        "\n",
        "# Create the parallel categories plot\n",
        "pio.renderers.default = \"notebook_connected\"\n",
        "\n",
        "fig = px.parallel_categories(\n",
        "    agg_df,\n",
        "    dimensions=['GrLivArea', 'OverallQual', 'GarageArea', 'TotalBsmtSF', 'YearBuilt'],\n",
        "    color=\"SalePrice\",\n",
        "    color_continuous_scale=px.colors.sequential.Viridis\n",
        ")\n",
        "\n",
        "fig.update_layout(margin=dict(l=100, r=100, t=50, b=50))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusions and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We identified a set of variables with strong correlation to `SalePrice`, including `GrLivArea`, `OverallQual`, `GarageArea`, and `TotalBsmtSF`. These correlations suggest that **larger, higher-quality homes with substantial garage and basement space** tend to sell for more in the Ames housing market.\n",
        "\n",
        "More specifically:\n",
        "- Homes with **larger above-ground living areas** (`GrLivArea`) are associated with higher sale prices.\n",
        "- Properties rated with a **higher overall quality of materials and finishes** (`OverallQual`) consistently show higher market value.\n",
        "- Houses with **larger garage areas** (`GarageArea`) are more valuable — likely reflecting convenience, storage space, or multi-car capacity.\n",
        "- A **larger basement area** (`TotalBsmtSF`) is also linked to increased sale price, suggesting that additional usable space adds value even if it’s not above ground.\n",
        "\n",
        "These findings align with real-world expectations: buyers typically pay more for homes that are spacious, well-built, and offer additional amenities like large garages or basements.\n",
        "\n",
        "- Variables with natural ordering (like `KitchenQual`) were encoded appropriately to preserve their meaning in correlation studies.\n",
        "- Missing values were handled to enable encoding and correlation computations.\n",
        "- Correlation was applied safely by selecting only numeric columns.\n",
        "- Scatter plots confirmed positive linear or monotonic trends between these features and house prices.\n",
        "\n",
        "**Next Steps:**\n",
        "- Clean and preprocess the selected features (e.g., handle remaining missing values)\n",
        "- Begin building and evaluating ML models for house price prediction (Business Requirement 2)\n",
        "- Integrate insights and visuals into the Streamlit dashboard"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
