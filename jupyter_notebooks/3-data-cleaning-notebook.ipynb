{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf514fb9",
   "metadata": {},
   "source": [
    "\n",
    "# Data Cleaning Notebook – Heritage Housing Prices\n",
    "\n",
    "## Objectives\n",
    "\n",
    "This notebook prepares the dataset for machine learning modeling by:\n",
    "\n",
    "- Identifying and evaluating missing values\n",
    "- Creating a plan to handle missing values\n",
    "- Splitting the data into training and testing sets\n",
    "- Dropping sparse or non-predictive features\n",
    "- Saving cleaned datasets for modeling\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- Original dataset\n",
    "  - outputs\\datasets\\collection\\house_prices_records.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Generate cleaned Train and Test sets:\n",
    "  - outputs\\datasets\\cleaned\\TrainSetCleaned.csv\n",
    "  - outputs\\datasets\\cleaned\\TestSetCleaned.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed4aeb1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457cc7c",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca3dacc",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a581a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b414ab87",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* `os.path.dirname()` gets the parent directory\n",
    "* `os.chir()` defines the new current directory\n",
    "\n",
    "Then we confirm the new current directory by printing it with `os.getcwd()` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab7f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"New working directory set to:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e49547",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea870d9",
   "metadata": {},
   "source": [
    "# Load Collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_raw_path = \"outputs/datasets/collection/house_prices_records.csv\"\n",
    "df = pd.read_csv(df_raw_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb77ec04",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754f3ee4",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c9d1c",
   "metadata": {},
   "source": [
    "In this section, we are interested in checking the distribution and shape of variables with missing data.\n",
    "\n",
    "So we list all variables with missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
    "vars_with_missing_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6c053",
   "metadata": {},
   "source": [
    "Then we create a profile with the variables with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "if vars_with_missing_data:\n",
    "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
    "    profile.to_notebook_iframe()\n",
    "else:\n",
    "    print(\"There are no variables with missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c35d87c",
   "metadata": {},
   "source": [
    "# Correlation and PPS Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d441373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ppscore as pps\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        mask[abs(df) < threshold] = True\n",
    "\n",
    "        fig, axes = plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
    "                    linewidth=0.5\n",
    "                    )\n",
    "        axes.set_yticklabels(df.columns, rotation=0)\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=bool)\n",
    "        mask[abs(df) < threshold] = True\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
    "                         linewidth=0.05, linecolor='grey')\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def CalculateCorrAndPPS(df):\n",
    "    df_corr_spearman = df.corr(method=\"spearman\", numeric_only=True)\n",
    "    df_corr_pearson = df.corr(method=\"pearson\", numeric_only=True)\n",
    "\n",
    "    import warnings\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning) # Ignore FutureWarning for ppscore to improve readability\n",
    "        pps_matrix_raw = pps.matrix(df)\n",
    "        pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "        pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "        print(\"\\nPPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
    "        print(pps_score_stats.round(3))\n",
    "\n",
    "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
    "\n",
    "\n",
    "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
    "                      figsize=(20, 12), font_annot=8):\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
    "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
    "    print(\"It evaluates monotonic relationship \\n\")\n",
    "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
    "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
    "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
    "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
    "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
    "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bedef5",
   "metadata": {},
   "source": [
    "Calculate Correlations and Power Predictive Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be10cd4",
   "metadata": {},
   "source": [
    "- 50% of all PPS are 0, that means that most feature-to-feature relationships show no predictive power\n",
    "\n",
    "- 75% are below 0.06 → only 25% of relationships have a PPS above 0.06\n",
    "\n",
    "- Only a few values go above 0.2\n",
    "\n",
    "So by setting the threshold at 0.2, we're:\n",
    "\n",
    "- Showing only the top ~5–10% of predictive relationships\n",
    "\n",
    "- Highlighting strong signals\n",
    "\n",
    "- Avoiding a cluttered heatmap\n",
    "\n",
    "It aligns well with the IQR logic (75% of scores are below 0.06 — so 0.2 is well into the upper tail).\n",
    "\n",
    "The histogram plots below highlight the threshold (red dashed line) in the distribution of PPS scores. The second plot is meant to highlight real variation by excluding 0.0 and 1.0. The histograms make it visually clear that only a small portion of the scores will be used for the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f995f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Flatten the PPS matrix to extract all PPS scores and remove NaNs\n",
    "pps_scores = pps_matrix.values.flatten()\n",
    "pps_scores = pps_scores[~np.isnan(pps_scores)]\n",
    "\n",
    "threshold = 0.2  # Define the threshold line\n",
    "\n",
    "# Filtered version (excluding 0.0 and 1.0)\n",
    "filtered_pps_scores = pps_scores[(pps_scores != 0.0) & (pps_scores != 1.0)]\n",
    "\n",
    "# Create side-by-side subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "# Plot 1: Full PPS distribution\n",
    "sns.histplot(pps_scores, bins=60, kde=True, ax=axes[0])\n",
    "axes[0].axvline(threshold, color='red', linestyle='--', label='Threshold = 0.2')\n",
    "axes[0].set_title(\"PPS Score Distribution (All Values)\")\n",
    "axes[0].set_xlabel(\"PPS\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot 2: Filtered PPS distribution\n",
    "sns.histplot(filtered_pps_scores, bins=60, kde=True, ax=axes[1])\n",
    "axes[1].axvline(threshold, color='red', linestyle='--', label='Threshold = 0.2')\n",
    "axes[1].set_title(\"PPS Score Distribution (Excluding 0.0 and 1.0)\")\n",
    "axes[1].set_xlabel(\"PPS\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e78e5e",
   "metadata": {},
   "source": [
    "Display Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
    "                  df_corr_spearman = df_corr_spearman, \n",
    "                  pps_matrix = pps_matrix,\n",
    "                  CorrThreshold = 0.5, PPS_Threshold = 0.2,\n",
    "                  figsize=(12,10), font_annot=10)\n",
    "\n",
    "high_corr_features = df_corr_spearman['SalePrice'][df_corr_spearman['SalePrice'] > threshold].index.tolist()\n",
    "print(\"\\nFeatures with correlation above the threshold to SalePrice:\\n\")\n",
    "print(high_corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1ea51c",
   "metadata": {},
   "source": [
    "### Top Predictors of SalePrice\n",
    "\n",
    "| Features most correlated with sales price | Spearman  | Pearson | PPS |\n",
    "|-------------------------------------------|-----------|---------|-----|\n",
    "| `1stFlrSF`                                | ✅       | ✅      | ❌  |\n",
    "| `GarageArea`                              | ✅       | ✅      | ❌  |\n",
    "| `GarageYrBlt`                             | ✅       | ❌      | ❌  |\n",
    "| `GrLivArea`                               | ✅       | ✅      | ❌  |\n",
    "| `KitchenQual`                             | ❌       | ❌      | ✅  |\n",
    "| `OverallQual`                             | ✅       | ✅      | ✅  |\n",
    "| `TotalBsmtSF`                             | ✅       | ✅      | ❌  |\n",
    "| `YearBuilt`                               | ✅       | ✅      | ❌  |\n",
    "| `YearRemodAdd`                            | ✅       | ✅      | ❌  |\n",
    "\n",
    "All three methods consistently highlight the following variables as highly predictive of house prices:\n",
    "\n",
    "- `OverallQual` (Quality of materials/finish)\n",
    "\n",
    "While both **Spearman** and **Person** put the following variables above the threshold:\n",
    "\n",
    "- `1stFlrSF` (1st floor area in square feet)\n",
    "- `GarageArea`\n",
    "- `GrLivArea` (Above-ground living area)\n",
    "- `TotalBsmtSF` (Basement area)\n",
    "- `YearBuilt`\n",
    "- `YearRemodAdd`\n",
    "\n",
    "These features seem like good candidates to retain for model development.\n",
    "\n",
    "### Multicollinearity Considerations\n",
    "\n",
    "Some variables are strongly correlated with each other, which may cause multicollinearity in linear models:\n",
    "\n",
    "- `GarageYrBuilt` ↔ `YearBuilt` (0.7)\n",
    "- `YearBuilt` ↔ `GarageYrBuilt` (0.63)\n",
    "- `1stFlrSF` ↔ `TotalBsmtSF` (0.58)\n",
    "- `GarageArea` ↔ `GrLivArea` (0.57)\n",
    "- `KitchenQual` ↔ `OverallQual` (0.53)\n",
    "- `KitchenQual` ↔ `YearBuilt` (0.47)\n",
    "\n",
    "In all heatmaps, we observe that the features are correlated with each other and exhibit predictive power among themselves. As a result, they provide redundant information for predicting the target variable, which increases the risk of overfitting the model. To address this, the next notebook will include a step to eliminate any excessively correlated features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec1425",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38017405",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d38102",
   "metadata": {},
   "source": [
    "## Assessing Missing Data Levels\n",
    "\n",
    "- Custom function to display missing data levels in a DataFrame, it shows the absolute levels, relative levels and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_missing_data(df):\n",
    "    missing_abs = df.isnull().sum()\n",
    "    missing_pct = round(missing_abs / len(df) * 100, 2)\n",
    "    df_missing_data = (pd.DataFrame(\n",
    "                            data={\"RowsWithMissingData\": missing_abs,\n",
    "                                   \"PercentageOfDataset\": missing_pct,\n",
    "                                   \"DataType\": df.dtypes}\n",
    "                                    )\n",
    "                          .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
    "                          .query(\"PercentageOfDataset > 0\")\n",
    "                          )\n",
    "\n",
    "    return df_missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba66352",
   "metadata": {},
   "source": [
    "Check missing data levels for the collected dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20003ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_missing_data(df)\n",
    "print(\"\\n\")\n",
    "print(evaluate_missing_data(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d04462",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c59a2d",
   "metadata": {},
   "source": [
    "# Dealing with missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39934980",
   "metadata": {},
   "source": [
    "## Dropping Sparse Features\n",
    "\n",
    "Based on the profiling report, we reviewed each variable with missing values and made decisions grounded in their:\n",
    "\n",
    "- Missing percentage\n",
    "- Predictive value potential\n",
    "- Domain relevance\n",
    "\n",
    "### Features to Drop:\n",
    "\n",
    "- **`EnclosedPorch`** – 90.7% missing  \n",
    "  Too sparse to be useful. Even if imputed, it would contribute noise rather than signal.\n",
    "\n",
    "- **`WoodDeckSF`** – 89.4% missing  \n",
    "  Very low coverage and low variability among non-missing values. Similar to `EnclosedPorch`, better removed.\n",
    "\n",
    "These features are dropped to simplify the dataset and avoid bias or overfitting due to poor-quality data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_drop = ['EnclosedPorch', 'WoodDeckSF']\n",
    "\n",
    "print(f\"Variables to drop: {variables_to_drop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be58fed6",
   "metadata": {},
   "source": [
    "## Impute Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1935bd1",
   "metadata": {},
   "source": [
    "Before any modeling or transformation can occur, it's essential to address missing data. This ensures model compatibility and avoids distortions during encoding and scaling. \n",
    "\n",
    "We begin by identifying variables with missing values and apply suitable imputation strategies based on the variable type and domain knowledge. Where relevant, we also add binary indicators to flag imputed values for potential predictive insight.\n",
    "We apply imputation strategies based on data type and domain understanding.\n",
    "\n",
    "We see that there are 64 instances of 'Zero' in `GarageArea` and 64 empty instances in `GarageYrBlt`, leading us to infer that the missing data in `GarageYrBlt` relates to the lack of a garage in that house.\n",
    "\n",
    "We start by handling missing values before encoding or scaling. This includes:\n",
    "\n",
    "- Using grouped median imputation for `LotFrontage`\n",
    "- Using constant values where missingness signals absence\n",
    "  - `0` for numeric features\n",
    "  - `\"None\"` for categorical features \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a1ea3",
   "metadata": {},
   "source": [
    "### Imputation Plan\n",
    "\n",
    "| Feature         | Rows With Missing Data | Percentage Of Dataset | Data Type | Metadata Insight                                         | Strategy       | Notes                                                                 |\n",
    "|:---------------:|:-------------------:|:--------------------:|:--------:|:----------------:|:--------:|:-----:|\n",
    "| `LotFrontage`   | 259                 | 17.74                | float64  | Linear feet of street connected to property               | Median         | Group median                                                          |\n",
    "| `GarageYrBlt`   | 81                  | 5.55                 | float64  | Year garage was built (1900–2010); missing if no garage   | Fill with `0`  | 0 clearly means no garage (can also flag with new feature if needed) |\n",
    "| `2ndFlrSF`      | 86                  | 5.89                 | float64  | Square footage of second floor (0–2065); 0 is common      | Fill with `0`  | No imputation needed — zero is valid                                 |\n",
    "| `MasVnrArea`    | 8                   | 0.55                 | float64  | Masonry veneer area (0–1600); 0 means no veneer           | Fill with `0`  | 0 is semantically meaningful                                          |\n",
    "| `BedroomAbvGr`  | 99                  | 6.78                 | float64  | Bedrooms above ground; 0–8 range                          | Median         | Could also test for mode; median is fine                             |\n",
    "| `BsmtExposure`  | 38                  | 2.60                 | object   | Exposure rating or `\"None\"` for no basement               | Fill with `\"None\"` | Use `\"None\"` instead of \"Missing\" to match domain encoding           |\n",
    "| `BsmtFinType1`  | 145                 | 9.93                 | object   | Finish type or `\"None\"` if no basement                    | Fill with `\"None\"` | `\"None\"` is an actual category in metadata                          |\n",
    "| `GarageFinish`  | 235                 | 16.10                | object   | Garage interior finish or `\"None\"` if no garage           | Fill with `\"None\"` | Use `\"None\"` for clarity and alignment with domain semantics        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb264476",
   "metadata": {},
   "source": [
    "## Split Train and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cde49e",
   "metadata": {},
   "source": [
    "We split the dataset before cleaning to avoid data leakage.\n",
    "\n",
    "This ensures that:\n",
    "\n",
    "- All cleaning decisions (like which variables to drop) are based solely on the training data\n",
    "\n",
    "- The test set remains a realistic “unseen” sample to evaluate model performance\n",
    "\n",
    "- We simulate what would happen in a real-world deployment, where new data is cleaned using a process built on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83bef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TrainSet, TestSet = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"TrainSet shape: {TrainSet.shape}\")\n",
    "print(f\"TestSet shape: {TestSet.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcc198a",
   "metadata": {},
   "source": [
    "- We put together the feature drop, numerical and categorical impute steps in out pipeline.\n",
    "- We create another DataFrame applying the imputations in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed30eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline \n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.imputation import ArbitraryNumberImputer\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "from feature_engine.selection import DropFeatures\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "variables_to_drop = ['EnclosedPorch', 'WoodDeckSF']\n",
    "numerical_impute_median = ['BedroomAbvGr', \"LotFrontage\"]\n",
    "numerical_impute_zero = ['2ndFlrSF', 'MasVnrArea', 'GarageYrBlt']\n",
    "categorical_fill_none = ['GarageFinish', 'BsmtFinType1', 'BsmtExposure']\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('drop', DropFeatures(features_to_drop=variables_to_drop)),\n",
    "    ('median', MeanMedianImputer(imputation_method='median', variables=numerical_impute_median)),\n",
    "    ('zero', ArbitraryNumberImputer(arbitrary_number=0, variables=numerical_impute_zero)),\n",
    "    ('cat', CategoricalImputer(imputation_method='missing', fill_value=\"None\", variables=categorical_fill_none))\n",
    "])\n",
    "\n",
    "\n",
    "df_method = pipeline.fit_transform(TrainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0440ec8e",
   "metadata": {},
   "source": [
    "We then confirm that there's no missing values in the new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_method.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e0d60",
   "metadata": {},
   "source": [
    "Using a custom function, we assess the effect on the variable's distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336892a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
    "\n",
    "  flag_count=1 # Indicate plot number\n",
    "  \n",
    "  # distinguish between numerical and categorical variables\n",
    "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns \n",
    "\n",
    "  # scan over variables, \n",
    "    # first on variables that you applied the method\n",
    "    # if the variable is a numerical plot, a histogram if categorical plot a barplot\n",
    "  for set_of_variables in [variables_applied_with_method]:\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"\\n=====================================================================================\")\n",
    "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
    "    print(f\"{set_of_variables} \\n\\n\")\n",
    "  \n",
    "\n",
    "    for var in set_of_variables:\n",
    "      if var in categorical_variables:  # it is categorical variable: barplot\n",
    "        \n",
    "        # df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
    "        # df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
    "        df1 = pd.DataFrame({\"Type\": \"Original\", \"Value\": df_original[var].astype(str)})\n",
    "        df2 = pd.DataFrame({\"Type\": \"Cleaned\", \"Value\": df_cleaned[var].astype(str)})\n",
    "\n",
    "        dfAux = pd.concat([df1, df2], axis=0)\n",
    "        fig , axes = plt.subplots(figsize=(15, 5))\n",
    "        sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"])\n",
    "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.legend() \n",
    "\n",
    "      else: # it is numerical variable: histogram\n",
    "\n",
    "        fig , axes = plt.subplots(figsize=(10, 5))\n",
    "        sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\", ax=axes)\n",
    "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\", ax=axes)\n",
    "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
    "        plt.legend() \n",
    "\n",
    "      plt.show()\n",
    "      flag_count+= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4944b",
   "metadata": {},
   "source": [
    "We put together the affected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbbc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_applied_with_method = numerical_impute_median + numerical_impute_zero + categorical_fill_none\n",
    "\n",
    "print(variables_applied_with_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d648f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataCleaningEffect(df_original=TrainSet, df_cleaned=df_method, variables_applied_with_method=variables_applied_with_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb573469",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b8ae5a",
   "metadata": {},
   "source": [
    "## Post-Imputation Correlation & PPS Check\n",
    "\n",
    "Now that we've imputed missing values and added flags, we reassess the feature relationships.\n",
    "\n",
    "This helps us:\n",
    "- Re-confirm top predictors of `SalePrice`\n",
    "- Detect any new multicollinearity\n",
    "\n",
    "We'll examine both:\n",
    "- **Pearson/Spearman correlation** (for linear and monotonic relationships)\n",
    "- **Power Predictive Score (PPS)** (for general predictive strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preview column data types\n",
    "print(\"Column data types after imputation:\")\n",
    "print(df_method.dtypes.value_counts())\n",
    "\n",
    "# 2. Get object columns for review\n",
    "object_cols = df_method.select_dtypes(include='object').columns.tolist()\n",
    "print(f\"\\nObject-type columns to review ({len(object_cols)}):\")\n",
    "print(object_cols)\n",
    "\n",
    "# 3. Get numeric columns for review\n",
    "numeric_cols = df_method.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(f\"\\nNumeric-type columns to review ({len(numeric_cols)}):\")\n",
    "print(numeric_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ffead",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning) # Ignore FutureWarning for ppscore to improve readability\n",
    "\n",
    "print(\"\\nOriginal Dataset\")\n",
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)\n",
    "\n",
    "print(\"\\n======================================================================================\")\n",
    "print(\"\\nCleaned Dataset\")\n",
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea73c7",
   "metadata": {},
   "source": [
    "After cleaning and imputing missing values, the number of evaluated feature pairs dropped (552 → 462) due to the removal of sparse columns. The overall mean and 75th percentile PPS slightly decreased, indicating a minor reduction in average predictive strength — a normal trade-off when replacing missing data with constants.\n",
    "\n",
    "Interestingly, the maximum PPS increased from 0.702 to 0.885, revealing that certain feature relationships became significantly stronger once missing values were filled. This suggests that the cleaning process helped uncover clearer predictive signals that were previously hidden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb76f13",
   "metadata": {},
   "source": [
    "### Display Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
    "                  df_corr_spearman = df_corr_spearman, \n",
    "                  pps_matrix = pps_matrix,\n",
    "                  CorrThreshold = 0.5, PPS_Threshold = 0.2,\n",
    "                  figsize=(12,10), font_annot=10)\n",
    "\n",
    "high_corr_features = df_corr_spearman['SalePrice'][df_corr_spearman['SalePrice'] > threshold].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336fe06",
   "metadata": {},
   "source": [
    "#### Correlation Analysis: Before vs After Data Cleaning\n",
    "\n",
    "After imputing missing values and removing sparse features, the correlation patterns shifted slightly. Spearman and Pearson scores remained largely stable for core predictive features, but Power Predictive Score (PPS) uncovered stronger signals in some imputed variables.\n",
    "\n",
    "- Most top predictors maintained or slightly increased their correlation with `SalePrice`.\n",
    "- **PPS scores** for some features (e.g., `OverallQual`, `YearBuilt`) improved post-cleaning, as imputed values allowed for clearer detection of predictive relationships.\n",
    "- Features with poor data quality that might have introduced noise (e.g., `EnclosedPorch`, `WoodDeckSF`) were dropped, resulting in a clearer correlation structure.\n",
    "- The rise in **maximum PPS score (0.702 → 0.885)** supports the notion that imputation helped uncover high-value relationships previously hidden due to missing data.\n",
    "\n",
    "#### Updated Top Predictors of `SalePrice` (After Cleaning)\n",
    "\n",
    "| Features most correlated with sales price | Spearman | Pearson  | PPS |\n",
    "|-------------------------------------------|----------|----------|-----|\n",
    "| `1stFlrSF`                                | ✅       | ✅      | ❌  |\n",
    "| `GarageArea`                              | ✅       | ✅      | ❌  |\n",
    "| `GarageYrBlt`                             | ✅       | ✅      | ❌  |\n",
    "| `GrLivArea`                               | ✅       | ✅      | ❌  |\n",
    "| `KitchenQual`                             | ✅       | ✅      | ✅  |\n",
    "| `OverallQual`                             | ✅       | ✅      | ✅  |\n",
    "| `TotalBsmtSF`                             | ✅       | ✅      | ❌  |\n",
    "| `YearBuilt`                               | ✅       | ✅      | ✅  |\n",
    "| `YearRemodAdd`                            | ✅       | ✅      | ❌  |\n",
    "\n",
    "#### Key Differences from Original Correlation Check\n",
    "\n",
    "| Feature        | Change Observed                            |\n",
    "|----------------|--------------------------------------------|\n",
    "| `KitchenQual`  | Now shows correlation in all three methods |\n",
    "| `GarageYrBlt`  | Pearson correlation improved               |\n",
    "| `YearBuilt`    | PPS score improved post-imputation         |\n",
    "| `OverallQual`  | Consistently strong — remains top predictor|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7025a84",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f29a17",
   "metadata": {},
   "source": [
    "# Save Cleaned Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c61123",
   "metadata": {},
   "source": [
    "Here we create create outputs/datasets/collection folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bb7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"outputs/datasets/cleaned\", exist_ok=True)\n",
    "    TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)\n",
    "    TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)\n",
    "except Exception as e:\n",
    "    print(f\"Error creating directories or saving files: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ab4a5",
   "metadata": {},
   "source": [
    "# Push cleaned data to Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390965c",
   "metadata": {},
   "source": [
    "You can now push the changes to your GitHub repository, using the Git commands (git add, git commit, git push)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aac488",
   "metadata": {},
   "source": [
    "## Conclusions and Next Steps\n",
    "\n",
    "- Identified variables with missing data and evaluated their type and proportion.\n",
    "- Dropped `EnclosedPorch` and `WoodDeckSF` due to sparsity and low predictive potential.\n",
    "- Split dataset into training and testing subsets before applying any modeling logic.\n",
    "- Saved cleaned datasets for reuse in the upcoming modeling notebook.\n",
    "\n",
    "In the next notebook, we’ll:\n",
    "- Impute remaining missing values\n",
    "- Encode categorical features\n",
    "- Perform feature scaling and model training\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
