{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modeling and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "This notebook focuses on training, optimizing, and evaluating a regression model that predicts the **sale price of houses** in Ames, Iowa. It is the core modeling step for **Business Requirement 2**, where the client wants to estimate property values based on known house attributes.\n",
        "\n",
        "Key goals include:\n",
        "- Selecting a subset of features that most strongly predict sale price\n",
        "- Trying multiple regression models and choosing the most effective\n",
        "- Evaluating the model using RÂ², MAE, RMSE, and visualization\n",
        "- Saving the model pipeline for deployment in the Streamlit app\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- outputs\\datasets\\cleaned\\TrainSetCleaned.csv\n",
        "- outputs\\datasets\\cleaned\\TestSetCleaned.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- `X_train.csv` and `X_test.csv`: Train/test sets with selected features\n",
        "- `y_train.csv` and `y_test.csv`: Corresponding targets (SalePrice)\n",
        "- Fitted regression pipeline (`best_regressor_pipeline.pkl`)\n",
        "- Feature importance plot (`feature_importance.png`)\n",
        "- Evaluation metrics and model summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with `os.getcwd()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* `os.path.dirname()` gets the parent directory\n",
        "* `os.chir()` defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "print(\"New working directory set to:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/house_prices_records.csv\")\n",
        "      .drop(labels=['EnclosedPorch', 'WoodDeckSF'], axis=1)\n",
        "  )\n",
        "\n",
        "print(df.shape)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Pipeline with all data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create ML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a flexible and modular ML pipeline using `sklearn.pipeline`. This pipeline includes encoding, transformations, multicollinearity reduction, scaling, feature selection, and the model itself.\n",
        "\n",
        "All transformation steps are based on decisions made in the Feature Engineering notebook, including:\n",
        "- Ordinal encoding for 4 categorical features\n",
        "- Log, power, and Yeo-Johnson transformations for skewed numeric features\n",
        "- SmartCorrelatedSelection with threshold = 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Feature Engineering\n",
        "from feature_engine.imputation import ArbitraryNumberImputer, MeanMedianImputer, CategoricalImputer\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine.transformation import LogTransformer, PowerTransformer, YeoJohnsonTransformer\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "\n",
        "# Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# ML algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def PipelineOptimization(model):\n",
        "    num_impute_zero = ['2ndFlrSF', 'MasVnrArea', 'GarageYrBlt']\n",
        "    num_impute_median = ['BedroomAbvGr', 'LotFrontage']\n",
        "    cat_impute_missing = ['BsmtExposure', 'BsmtFinType1', 'GarageFinish']\n",
        "    ordinal_encode = ['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']\n",
        "\n",
        "    log_transform = ['GrLivArea']\n",
        "    log10_transform = ['1stFlrSF']\n",
        "    yeojohnson_transform = ['GarageArea', 'LotFrontage', '1stFlrSF']\n",
        "    power_transform = ['TotalBsmtSF']\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        (\"num_zero\", ArbitraryNumberImputer(arbitrary_number=0, variables=num_impute_zero)),\n",
        "        (\"num_median\", MeanMedianImputer(imputation_method='median', variables=num_impute_median)),\n",
        "        (\"cat_missing\", CategoricalImputer(imputation_method='missing', variables=cat_impute_missing)),\n",
        "\n",
        "        (\"ordinal_encoder\", OrdinalEncoder(encoding_method='arbitrary', variables=ordinal_encode)),\n",
        "\n",
        "        (\"log_transform\", LogTransformer(variables=log_transform)),\n",
        "        (\"log10_transform\", LogTransformer(variables=log10_transform, base='10')),\n",
        "        (\"yeojohnson\", YeoJohnsonTransformer(variables=yeojohnson_transform)),\n",
        "        (\"power_transform\", PowerTransformer(variables=power_transform)),\n",
        "\n",
        "        (\"correlation_filter\", SmartCorrelatedSelection(\n",
        "            method='spearman',\n",
        "            threshold=0.8,\n",
        "            selection_method='variance')),\n",
        "        \n",
        "        (\"feat_scaling\", StandardScaler()),\n",
        "\n",
        "        (\"feat_selection\",  SelectFromModel(model)),\n",
        "\n",
        "        (\"model\", model),\n",
        "    ])\n",
        "\n",
        "    return pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Custom Class for hyperparameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model = PipelineOptimization(self.models[key])\n",
        "\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring)\n",
        "            gs.fit(X, y)\n",
        "            self.grid_searches[key] = gs\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                'estimator': key,\n",
        "                'min_score': min(scores),\n",
        "                'max_score': max(scores),\n",
        "                'mean_score': np.mean(scores),\n",
        "                'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params, **d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]\n",
        "                scores.append(r.reshape(len(params), 1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params, all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score',\n",
        "                   'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns], self.grid_searches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Train Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(['SalePrice'], axis=1),\n",
        "    df['SalePrice'],\n",
        "    test_size=0.2,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
        "      \"\\n* Test set:\",  X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search CV - Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use default hyperparameters to find most suitable algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "models_quick_search = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    'LinearRegression': {},\n",
        "    \"DecisionTreeRegressor\": {},\n",
        "    \"RandomForestRegressor\": {},\n",
        "    \"ExtraTreesRegressor\": {},\n",
        "    \"AdaBoostRegressor\": {},\n",
        "    \"GradientBoostingRegressor\": {},\n",
        "    \"XGBRegressor\": {},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Perform Quick Hyperparameter Search\n",
        "\n",
        "This cell uses the `HyperparameterOptimizationSearch` class to perform a quick grid search over default hyperparameters for multiple regression models. The goal is to identify the most suitable algorithm for predicting house prices. The search evaluates models using 5-fold cross-validation and the RÂ² scoring metric. Results will help determine which model to focus on for further optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Do an extensive search on the most suitable model to find the best hyperparameter configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define model and parameters, for Extensive Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "javascript"
        }
      },
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "}\n",
        "\n",
        "params_search = {\n",
        "    \"ExtraTreesRegressor\": {\n",
        "        'model__n_estimators': [100, 200],\n",
        "        'model__max_depth': [10, 20],\n",
        "        'model__min_samples_split': [2, 5],\n",
        "        'model__min_samples_leaf': [1, 2],\n",
        "    },\n",
        "    \"LinearRegression\": {\n",
        "        'model__fit_intercept': [True],\n",
        "    },\n",
        "    \"RandomForestRegressor\": {\n",
        "        'model__n_estimators': [100, 200],\n",
        "        'model__max_depth': [10, 20],\n",
        "        'model__min_samples_split': [2, 5],\n",
        "        'model__min_samples_leaf': [1, 2],\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extensive GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "# Suppress FutureWarnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[0, 0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameters for best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the best regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assess feature importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We visualize the top 5 most important features according to the ExtraTreesRegressor model. These are the features that contributed most to predicting house prices.\n",
        "\n",
        "This helps:\n",
        "- Understand what drives model decisions\n",
        "- Align findings with domain knowledge\n",
        "- Potentially drop weak features in future optimization\n",
        "\n",
        "As expected, features like overall quality (`OverallQual`), above-ground living area (`GrLivArea`), and garage size (`GarageArea`) are key contributors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "# Suppress FutureWarnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "data_cleaning_feat_eng_steps = 9\n",
        "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
        "                                        .transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
        ")].to_list()\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
        "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
        "    .sort_values(by='Importance', ascending=False)\n",
        ")\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the chart above, we observe that `OverallQual` dominates in importance, indicating that overall construction and finish quality are the strongest indicator of sale price in Ames, Iowa. This insight could also guide further feature selection or transformation in future iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Regressor on Train and Tests Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Suppress FutureWarnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
        "    print(\"Model Evaluation \\n\")\n",
        "    print(\"* Train Set\")\n",
        "    regression_evaluation(X_train, y_train, pipeline)\n",
        "    print(\"* Test Set\")\n",
        "    regression_evaluation(X_test, y_test, pipeline)\n",
        "\n",
        "\n",
        "def regression_evaluation(X, y, pipeline):\n",
        "    prediction = pipeline.predict(X)\n",
        "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
        "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
        "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
        "    print('Root Mean Squared Error:', np.sqrt(\n",
        "        mean_squared_error(y, prediction)).round(3))\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
        "    pred_train = pipeline.predict(X_train)\n",
        "    pred_test = pipeline.predict(X_test)\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
        "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
        "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
        "    axes[0].set_xlabel(\"Actual\")\n",
        "    axes[0].set_ylabel(\"Predictions\")\n",
        "    axes[0].set_title(\"Train Set\")\n",
        "\n",
        "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
        "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
        "    axes[1].set_xlabel(\"Actual\")\n",
        "    axes[1].set_ylabel(\"Predictions\")\n",
        "    axes[1].set_title(\"Test Set\")\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test,\n",
        "                            best_regressor_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Refit a Simpler Pipeline with Only Top Features\n",
        "\n",
        "We rebuild the pipeline using only the most important features to evaluate performance and interpretability trade-offs. This helps simplify the model without sacrificing too much accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rewrite Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PipelineTop5(model):\n",
        "    log_transform = ['GrLivArea']\n",
        "    yeojohnson_transform = ['GarageArea',]\n",
        "    power_transform = ['TotalBsmtSF']\n",
        "\n",
        "    pipeline_selected = Pipeline([\n",
        "        (\"log_transform\", LogTransformer(variables=log_transform)),\n",
        "        (\"yeojohnson\", YeoJohnsonTransformer(variables=yeojohnson_transform)),\n",
        "        (\"power_transform\", PowerTransformer(variables=power_transform)),\n",
        "        \n",
        "        (\"feat_scaling\", StandardScaler()),\n",
        "\n",
        "        (\"model\", model),\n",
        "    ])\n",
        "\n",
        "    return pipeline_selected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Train Test Set, only with best features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(['SalePrice'], axis=1),\n",
        "    df['SalePrice'],\n",
        "    test_size=0.2,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
        "      \"\\n* Test set:\",  X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subset Best Features\n",
        "\n",
        "We now limit the dataset to only the top 5 most important features (from the previous ExtraTrees model). This lets us test how much performance is retained with fewer predictors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train[best_features]\n",
        "X_test = X_test[best_features]\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\", X_test.shape, y_test.shape)\n",
        "X_train.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search CV â Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are using the same model from the previous GridCV search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_top5 = {\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we are gonna check for the best parameters just as in the previous GridCV search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params_search['ExtraTreesRegressor']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Hyperparameter Grid for Top 5 Features\n",
        "\n",
        "This cell defines the hyperparameter grid (`params_top5`) for the `ExtraTreesRegressor` model, which was identified as the best-performing model in the previous grid search.\n",
        "\n",
        "These hyperparameters will be used in a new grid search to optimize the model's performance when trained on the top 5 most important features. This step ensures that the model is fine-tuned for the reduced feature set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params_top5 = {\n",
        "    \"ExtraTreesRegressor\": {\n",
        "        \"model__n_estimators\": [100, 200],\n",
        "        \"model__max_depth\": [10, 20, None],\n",
        "        \"model__min_samples_split\": [2, 5],\n",
        "        \"model__min_samples_leaf\": [1, 2]\n",
        "    }\n",
        "}\n",
        "params_top5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "bat"
        }
      },
      "source": [
        "### Perform Hyperparameter Optimization for Top 5 Features\n",
        "\n",
        "The results of the grid search will help identify the best hyperparameter configuration for the `ExtraTreesRegressor` model when trained on the reduced feature set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_top5, params=params_top5)\n",
        "search.fit(X_train, y_train,\n",
        "                 scoring='r2',\n",
        "                 n_jobs=-1,\n",
        "                 cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View Results and Select Best Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model\n",
        "best_pipeline_top5 = grid_search_pipelines[best_model].best_estimator_\n",
        "best_pipeline_top5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assess feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "# Define the pipeline_selected using the best model\n",
        "pipeline_selected = PipelineOptimization(ExtraTreesRegressor(\n",
        "    max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100, random_state=0))\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline_selected.fit(X_train, y_train)\n",
        "\n",
        "# number of data cleaning and feature engineering steps in the pipeline\n",
        "data_cleaning_feat_eng_steps = 3\n",
        "columns_after_data_cleaning_feat_eng = (Pipeline(pipeline_selected.steps[:data_cleaning_feat_eng_steps])\n",
        "                                        .fit(X_train, y_train)\n",
        "                                        .transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "    'Feature': columns_after_data_cleaning_feat_eng,\n",
        "    'Importance': pipeline_selected['model'].feature_importances_})\n",
        "    .sort_values(by='Importance', ascending=False)\n",
        ")\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The importance levels are virtually unchanged in relation to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Classifier on Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regression_performance(X_train, y_train, X_test, y_test,best_pipeline_top5)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test,\n",
        "                            best_pipeline_top5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Although we dropped many features, the model performance remained stable, showing **slight increase in RÂ² Score from 0.84 to 0.844**. This suggests the removed features were not adding significant predictive value, confirming that ExtraTrees is robust and able to focus on strong predictors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save Artifacts for Deployment and Dashboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These outputs will allow the Streamlit app to:\n",
        "\n",
        "- Load the final trained pipeline\n",
        "- Access the top 5 features\n",
        "- Read input format from training data\n",
        "- Visualize model insights like feature importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Output Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "\n",
        "version = \"v1\"\n",
        "output_dir = f\"outputs/ml_pipeline/predict_house_price/{version}\"\n",
        "\n",
        "try:\n",
        "  os.makedirs(name=output_dir, exist_ok=True)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "print(f\"â Output directory created at: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save features\n",
        "X_train.to_csv(f\"{output_dir}/X_train.csv\", index=False)\n",
        "X_test.to_csv(f\"{output_dir}/X_test.csv\", index=False)\n",
        "\n",
        "# Save targets\n",
        "y_train.to_csv(f\"{output_dir}/y_train.csv\", index=False)\n",
        "y_test.to_csv(f\"{output_dir}/y_test.csv\", index=False)\n",
        "\n",
        "print(\"â Train/test sets saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Final Model Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=best_pipeline_top5, filename=f\"{output_dir}/pipeline_top5.pkl\")\n",
        "\n",
        "print(\"â Final model pipeline saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Feature Importance Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 5 features were already used to train the pipeline\n",
        "df_feature_importance_top5 = df_feature_importance[df_feature_importance[\"Feature\"].isin(X_train.columns)]\n",
        "\n",
        "df_feature_importance_top5.plot(kind='bar', x='Feature', y='Importance', figsize=(8, 4))\n",
        "plt.title(\"Top 5 Features - Feature Importance\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{output_dir}/feature_importance_top5.png\", bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"â Feature importance plot saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Feature List (for dashboard inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=list(X_train.columns), filename=f\"{output_dir}/feature_list.pkl\")\n",
        "\n",
        "print(\"â Feature list saved for dashboard.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save evaluation metrics to `.json`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "metrics = {\n",
        "    \"R2_train\": r2_score(y_train, best_pipeline_top5.predict(X_train)).round(3),\n",
        "    \"MAE_train\": mean_absolute_error(y_train, best_pipeline_top5.predict(X_train)).round(3),\n",
        "    \"RMSE_train\": np.sqrt(mean_squared_error(y_train, best_pipeline_top5.predict(X_train))).round(3),\n",
        "    \"R2_test\": r2_score(y_test, best_pipeline_top5.predict(X_test)).round(3),\n",
        "    \"MAE_test\": mean_absolute_error(y_test, best_pipeline_top5.predict(X_test)).round(3),\n",
        "    \"RMSE_test\": np.sqrt(mean_squared_error(y_test, best_pipeline_top5.predict(X_test))).round(3)\n",
        "}\n",
        "\n",
        "# Save to JSON file\n",
        "with open(f\"{output_dir}/model_metrics.json\", \"w\") as f:\n",
        "    json.dump(metrics, f, indent=4)\n",
        "\n",
        "print(\"â Model metrics saved as JSON.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
